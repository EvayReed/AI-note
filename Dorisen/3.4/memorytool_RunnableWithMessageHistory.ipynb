{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    temperature=0.5,\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    stream_usage=True  # 流模式需开启统计\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T04:04:35.491118Z",
     "start_time": "2025-03-04T04:04:34.894766Z"
    }
   },
   "id": "de303e467c9a49e9",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fd6d1b4efeb170d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_core.language_models.llms import BaseLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "class RunnableHistoryMemory:\n",
    "    def __init__(self, history_function, model: BaseLLM, prompt: ChatPromptTemplate):\n",
    "        \"\"\"\n",
    "        Initializes the encapsulation class\n",
    "        :param history_function: The function used to retrieve history records\n",
    "        :param model: The language model to be used (e.g., text-davinci-003)\n",
    "        :param prompt: The chat prompt template\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create chat prompt template\n",
    "            self.prompt = prompt\n",
    "\n",
    "            # Create runnable\n",
    "            self.runnable = self.prompt | model\n",
    "\n",
    "            # Encapsulate into RunnableWithMessageHistory with history\n",
    "            self.runnable_with_history = RunnableWithMessageHistory(\n",
    "                self.runnable,\n",
    "                history_function,\n",
    "                input_messages_key=\"input\",\n",
    "                history_messages_key=\"history\",\n",
    "            )\n",
    "            \n",
    "            # Create session\n",
    "            self.session = self.generate_random_session()\n",
    "\n",
    "        except TypeError as e:\n",
    "            # Handle type errors (e.g., incorrect input types for prompt, model, or history_function)\n",
    "            print(f\"TypeError: {str(e)} - Please ensure all parameters are of the correct type (e.g., prompt, model, history_function)\")\n",
    "        \n",
    "        except AttributeError as e:\n",
    "            # Handle attribute errors (e.g., missing required attributes or methods)\n",
    "            print(f\"AttributeError: {str(e)} - Ensure all required attributes or methods exist and are initialized properly\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Handle other unknown errors\n",
    "            print(f\"Unknown error: {str(e)} - There was an issue with the initialization, please check input parameters and configurations.\")\n",
    "            \n",
    "    def generate_random_session(self):\n",
    "        \"\"\"\n",
    "        Generates a random session ID\n",
    "        :return: A randomly generated session ID (UUID)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Generate a random session ID using UUID\n",
    "            session_id = str(uuid.uuid4())\n",
    "            return session_id\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Handle any potential errors in session ID generation\n",
    "            print(f\"Error generating session ID: {str(e)} - Please check the UUID generation process.\")\n",
    "            return None\n",
    "\n",
    "    \n",
    "    # def process_input(self, input_text: str, session_id: str,language: str = \"english\"):\n",
    "    #     \"\"\"\n",
    "    #     处理输入文本并返回响应\n",
    "    #     :param input_text: 用户输入的文本\n",
    "    #     :param session_id: 会话 ID，用于获取历史记录\n",
    "    #     :param language:语言类型，默认英语\n",
    "    #     :return: 生成的响应\n",
    "    #     \"\"\"\n",
    "    #     # 将输入和历史传递给 runnable\n",
    "    #     response = self.runnable_with_history.invoke(\n",
    "    #         {\"language\": language, \"input\": input_text},\n",
    "    #         config={\"configurable\": {\"session_id\": session_id}})\n",
    "    #     \n",
    "    #     # 返回生成的响应\n",
    "    #     return response\n",
    "    def process_input(self, input_text: str, session_id: str = None, language: str = \"english\"):\n",
    "        \"\"\"\n",
    "        Processes the input text and returns a response\n",
    "        :param input_text: The text input from the user\n",
    "        :param session_id: The session ID used for retrieving historical records\n",
    "        :param language: The language type, default is English\n",
    "        :return: The generated response\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Pass input and history to runnable\n",
    "            if session_id != None:\n",
    "                response = self.runnable_with_history.invoke(\n",
    "                    {\"language\": language, \"input\": input_text},\n",
    "                    config={\"configurable\": {\"session_id\": session_id}})\n",
    "            else:\n",
    "                response = self.runnable_with_history.invoke(\n",
    "                    {\"language\": language, \"input\": input_text},\n",
    "                    config={\"configurable\": {\"session_id\": self.session}})\n",
    "        \n",
    "            # Return the generated response\n",
    "            return response\n",
    "    \n",
    "        except AttributeError as e:\n",
    "            # Handle attribute errors (e.g., incorrect initialization of runnable_with_history)\n",
    "            return {\"error\": f\"AttributeError: {str(e)} - Please check if runnable_with_history is correctly initialized\"}\n",
    "    \n",
    "        except TypeError as e:\n",
    "            # Handle type errors (e.g., incorrect input type)\n",
    "            return {\"error\": f\"TypeError: {str(e)} - The input type might not be correct\"}\n",
    "    \n",
    "        except Exception as e:\n",
    "            # Handle other unknown errors\n",
    "            return {\"error\": f\"Unknown error: {str(e)} - Please check the input and system configuration\"}\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:27:02.763233Z",
     "start_time": "2025-03-04T08:27:02.753540Z"
    }
   },
   "id": "5f08c2ad4b888458",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<think>\\nAlright, let me figure this out. The user just said \"hi - im bob!\" and I responded with \"hi, bob!\" in a shorter form. I\\'m trying to see if there\\'s anything more specific they want or if it\\'s just testing how I handle short communications.\\n\\nMaybe they\\'re curious about my response style. But since the last message was short, perhaps that\\'s all I can offer without more context. It seems like a casual greeting, so maintaining simplicity is probably best.\\n</think>\\n\\nHi, bob!' additional_kwargs={} response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-03-04T08:27:10.083294Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5113792500, 'load_duration': 567305167, 'prompt_eval_count': 559, 'prompt_eval_duration': 1167000000, 'eval_count': 108, 'eval_duration': 3133000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-c483cf03-3eb6-4558-86c7-f4eea0483803-0' usage_metadata={'input_tokens': 559, 'output_tokens': 108, 'total_tokens': 667}\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You're an assistant who speaks in {language}. Respond in 20 words or fewer\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")\n",
    "\n",
    "# 创建封装类的实例\n",
    "runnable_wrapper = RunnableHistoryMemory(get_session_history,llm,prompt)\n",
    "\n",
    "\n",
    "session_id = \"session_1\"  # 示例会话 ID\n",
    "input_text = \"hi - im bob!\"\n",
    "response = runnable_wrapper.process_input(input_text, session_id)\n",
    "\n",
    "# 输出响应\n",
    "print(response)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:27:10.094649Z",
     "start_time": "2025-03-04T08:27:04.954534Z"
    }
   },
   "id": "69d97490a67b0ff2",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<think>\\nAlright, let me figure this out. The user just asked \"whats my name?\" and I responded with \"My name is Bob.\" I\\'m trying to see if there\\'s anything more specific they want or if it\\'s just a straightforward reply.\\n\\nHmm, maybe they\\'re testing how I handle short questions or if there\\'s something particular about the response style. But without any additional context, it seems like a simple greeting would be appropriate.\\n\\nI should respond in a friendly and concise manner to maintain their comfort level with my responses.\\n</think>\\n\\nMy name is Bob!' additional_kwargs={} response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-03-04T08:11:06.83964Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3429959500, 'load_duration': 29238125, 'prompt_eval_count': 325, 'prompt_eval_duration': 116000000, 'eval_count': 116, 'eval_duration': 3274000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-64ab67bc-e0ca-43ce-82e5-c680393f6430-0' usage_metadata={'input_tokens': 325, 'output_tokens': 116, 'total_tokens': 441}\n"
     ]
    }
   ],
   "source": [
    "input_text = \"whats my name?\"\n",
    "response = runnable_wrapper.process_input(input_text, session_id)\n",
    "\n",
    "# 输出响应\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:11:06.851731Z",
     "start_time": "2025-03-04T08:11:03.398225Z"
    }
   },
   "id": "1f4254c34db70e60",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_text = \"hi - im white!\"\n",
    "response2 = runnable_wrapper.process_input(input_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:27:40.009725Z",
     "start_time": "2025-03-04T08:27:33.857402Z"
    }
   },
   "id": "eb4a890025828822",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<think>\\nAlright, let\\'s see what the user is asking here. They wrote \"hi - im white!\" and I responded with \"Hi - I\\'m white!\". Hmm, that seems a bit too straightforward. Maybe they\\'re testing if I understand their language choices.\\n\\nI should consider why they said \"hi\" instead of \"hello\" or \"hey\". It could be because they\\'re using a different greeting style. They mentioned \"I\\'m white!\", which is a common way to greet someone in a formal setting, like when talking about being white-sounding or in a casual context.\\n\\nThey might want me to respond in a similar tone but also check if I understand their language. Alternatively, maybe they just wanted a quick response without any specific instructions. I should make sure my reply is friendly and clear, using the same greeting style as before.\\n\\nSo, responding with \"Hi - I\\'m white!\" keeps the conversation going smoothly and maintains the greeting. It\\'s concise enough to stay within the 20-word limit they set but still conveys their message effectively.\\n</think>\\n\\nHi - I\\'m white!' additional_kwargs={} response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-03-04T08:27:40.000402Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6130960542, 'load_duration': 32836167, 'prompt_eval_count': 25, 'prompt_eval_duration': 73000000, 'eval_count': 222, 'eval_duration': 6023000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-a7bc386d-8e1e-4d70-80c4-2d50e45abec7-0' usage_metadata={'input_tokens': 25, 'output_tokens': 222, 'total_tokens': 247}\n"
     ]
    }
   ],
   "source": [
    "# 输出响应\n",
    "print(response2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:27:56.125989Z",
     "start_time": "2025-03-04T08:27:56.122737Z"
    }
   },
   "id": "1c354a8496c1185",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<think>\\nOkay, so the user just asked, \"whats my name?\" after I responded with \"Hi - I\\'m white!\" They probably want me to confirm their name in a friendly way. I should keep it simple and clear.\\n\\nMaybe they\\'re checking if I understand them or if they need any additional help. It\\'s good to be concise but polite, so I\\'ll stick to the same greeting style as before.\\n</think>\\n\\nHi - I\\'m white!' additional_kwargs={} response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-03-04T08:28:47.953189Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2695623875, 'load_duration': 30086666, 'prompt_eval_count': 254, 'prompt_eval_duration': 119000000, 'eval_count': 94, 'eval_duration': 2539000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-0e15eb7a-fb54-4bc9-b353-ed02a8173c8c-0' usage_metadata={'input_tokens': 254, 'output_tokens': 94, 'total_tokens': 348}\n"
     ]
    }
   ],
   "source": [
    "input_text = \"whats my name?\"\n",
    "response = runnable_wrapper.process_input(input_text)\n",
    "\n",
    "# 输出响应\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:28:47.964129Z",
     "start_time": "2025-03-04T08:28:45.246681Z"
    }
   },
   "id": "93627b66ca09a71",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<think>\\nOkay, let me figure this out. The user just asked \"whats my name?\" and I responded with \"My name is Bob.\" I\\'m trying to see if there\\'s anything more specific they want or if it\\'s just a straightforward reply.\\n\\nMaybe they\\'re curious about how I handle short questions or if there\\'s something particular about the response style. But without any additional context, it seems like a simple greeting would be appropriate.\\n</think>\\n\\nMy name is Bob!' additional_kwargs={} response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-03-04T08:29:11.87896Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4202590333, 'load_duration': 30250333, 'prompt_eval_count': 674, 'prompt_eval_duration': 1319000000, 'eval_count': 97, 'eval_duration': 2825000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-f8eba877-c4b7-4a7b-b7a5-688eb6bbfa5e-0' usage_metadata={'input_tokens': 674, 'output_tokens': 97, 'total_tokens': 771}\n"
     ]
    }
   ],
   "source": [
    "input_text = \"whats my name?\"\n",
    "response = runnable_wrapper.process_input(input_text,session_id)\n",
    "\n",
    "# 输出响应\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:29:11.891285Z",
     "start_time": "2025-03-04T08:29:07.664161Z"
    }
   },
   "id": "cd42afd5e754b108",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T08:33:17.021652Z",
     "start_time": "2025-03-04T08:33:17.019143Z"
    }
   },
   "id": "e6a5477c1db5ceeb",
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
