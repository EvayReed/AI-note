{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    temperature=0.5,\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    stream_usage=True  # 流模式需开启统计\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T03:58:32.440975Z",
     "start_time": "2025-03-04T03:58:32.388457Z"
    }
   },
   "id": "4954368ecbd8ec5e",
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "source": [
    "这个是0.3版本的memory，主要是把chain换成了langgraph的形式，看输入抽象类一个是差不多的"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a9074001e8714a9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    # Update message history with response:\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T03:58:34.637131Z",
     "start_time": "2025-03-04T03:58:34.624734Z"
    }
   },
   "id": "deac77150babf7e8",
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": [
    "当我们运行应用程序时，我们传入一个dict指定 的配置thread_id。此 ID 用于区分对话线程（例如，在不同用户之间）。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9dfc0c283ec596"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T03:58:38.664574Z",
     "start_time": "2025-03-04T03:58:38.661544Z"
    }
   },
   "id": "6d87294ea99f0580",
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "source": [
    "然后我们可以调用该应用程序："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbf71fb6a926c86d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hello, Bob! How can I assist you today? 😊\n"
     ]
    }
   ],
   "source": [
    "query = \"Hi! I'm Bob.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T03:58:49.704928Z",
     "start_time": "2025-03-04T03:58:48.541314Z"
    }
   },
   "id": "45cc9ec8dfd053e6",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Greetings! My name is Bob. I'm an AI assistant created to provide helpful and harmless responses.\n"
     ]
    }
   ],
   "source": [
    "query = \"What's my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T03:58:53.875980Z",
     "start_time": "2025-03-04T03:58:52.825009Z"
    }
   },
   "id": "1902e2e4999defe",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hi! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I don't have access to personal information about users. For any inquiries, please go directly to DeepSeek-R1.\n"
     ]
    }
   ],
   "source": [
    "query = \"What's my name?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T04:00:37.423903Z",
     "start_time": "2025-03-04T04:00:36.076959Z"
    }
   },
   "id": "a54a9f8a1636057b",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: 你好啊\\nAI: 你也好啊'}\n",
      "{'history': 'Human: 你好啊\\nAI: 你也好啊\\nHuman: 你再好啊\\nAI: 你又好啊'}\n",
      "{'history': 'Human: 你好啊\\nAI: 你也好啊\\nHuman: 你再好啊\\nAI: 你又好啊\\nHuman: 你在干嘛\\nAI: 我在学习'}\n"
     ]
    }
   ],
   "source": [
    "#langchain 1.0.0 被remove了，比较简单的一个实现形式但是用不了\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory\n",
    "\n",
    "history = ConversationBufferMemory()\n",
    "history.save_context({\"input\": \"你好啊\"}, {\"output\": \"你也好啊\"})\n",
    "print(history.load_memory_variables({}))\n",
    "\n",
    "history.save_context({\"input\": \"你再好啊\"}, {\"output\": \"你又好啊\"})\n",
    "print(history.load_memory_variables({}))\n",
    "\n",
    "history.chat_memory.add_user_message(\"你在干嘛\")\n",
    "history.chat_memory.add_ai_message(\"我在学习\")\n",
    "print(history.load_memory_variables({}))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T04:00:46.727613Z",
     "start_time": "2025-03-04T04:00:46.722322Z"
    }
   },
   "id": "8243a8bcb4704497",
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bbc6fe17a2a9577d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "495f7a74f79704ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
